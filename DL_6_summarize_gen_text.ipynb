{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPyLflCNHt3c/6wiVhWh/sa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JPP-J/deep-_learning_project/blob/main/DL_6_summarize_gen_text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install relative libraries"
      ],
      "metadata": {
        "id": "6e7P5v41Tb4h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTkQQ5nALrwr",
        "outputId": "a1e1a47e-edb5-4524-d31a-236efac157bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n"
          ]
        }
      ],
      "source": [
        "pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model usage in this notebook\n",
        "* General Text Generation: GPT-2\n",
        "\n",
        "* BART (Bidirectional and Auto-Regressive Transformers)\n",
        "\n",
        "```\n",
        "summarize: \" + text\n",
        "```\n",
        "\n",
        "```\n",
        "translate English to French:\n",
        "```"
      ],
      "metadata": {
        "id": "fw_JlQS6Volt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generative task\n",
        "Using GPT-2 model"
      ],
      "metadata": {
        "id": "1zCz8VrCTzIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, pipeline\n",
        "\n",
        "# Load the GPT-2 tokenizer and model\n",
        "model_name_g = \"gpt2\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name_g)\n",
        "model_g = GPT2LMHeadModel.from_pretrained(model_name_g)\n",
        "\n",
        "# Function to summarize text\n",
        "def generate_text(text, max_length=512, num_beams=5):\n",
        "    \"\"\"\n",
        "    Summarize the input text using GPT-2.\n",
        "    :param text: str, input text to summarize\n",
        "    :param max_length: int, maximum length of the summary\n",
        "    :param num_beams: int, number of beams for beam search\n",
        "    :return: str, summarized text\n",
        "    \"\"\"\n",
        "    # Encode input text\n",
        "    inputs = tokenizer.encode(text, return_tensors=\"pt\", truncation=True, max_length=1024)\n",
        "\n",
        "    # Generate using beam search\n",
        "    summary_ids = model_g.generate(\n",
        "        inputs,\n",
        "        max_length=max_length,\n",
        "        num_beams=num_beams,\n",
        "        early_stopping=True,\n",
        "        no_repeat_ngram_size=2\n",
        "    )\n",
        "\n",
        "    # Decode generated tokens\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary"
      ],
      "metadata": {
        "id": "6U2s6q4BLunk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model GPT-2 Details"
      ],
      "metadata": {
        "id": "L4EChBGrU49c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_g"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bWptdvIYJ9R",
        "outputId": "d8ebd5c6-cfc6-4a01-93c0-d355ff274bf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50257, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2SdpaAttention(\n",
              "          (c_attn): Conv1D(nf=2304, nx=768)\n",
              "          (c_proj): Conv1D(nf=768, nx=768)\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D(nf=3072, nx=768)\n",
              "          (c_proj): Conv1D(nf=768, nx=3072)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example usage GPT-2"
      ],
      "metadata": {
        "id": "K0ZKyVAcU83Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage GPT-2\n",
        "input_text_g = 'write decription of house'\n",
        "generated_text = generate_text(input_text_g, max_length=1024)\n",
        "print(\"Original Text:\\n\", input_text_g)\n",
        "print(\"\\nGenerated Text:\\n\", generated_text)\n",
        "print(\"input length: \", len(input_text_g))\n",
        "print(\"out put length: \", len(generated_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TPuocRwTr9o",
        "outputId": "f2dd40c3-28e3-4b65-8f75-96c28c6f1033"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text:\n",
            " write decription of house\n",
            "\n",
            "Generated Text:\n",
            " write decription of house.\n",
            "\n",
            "The house was built in the late 19th century, and it is believed to have been built on the site of one of the most famous houses in London. The house is said to be the oldest house in Britain, dating back to the 17th Century. It is thought that it was used as a boarding house for the nobility, as well as being used by the royal family as an entertainment centre.\n",
            "\n",
            "\n",
            "It is estimated that the house cost £1.5m to build, with a total cost of £2.3m.\n",
            "input length:  25\n",
            "out put length:  474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summarize task\n",
        "Using bart model\n",
        "\n",
        "    facebook/bart-large-cnn: Fine-tuned for summarization tasks using the CNN/DailyMail dataset.\n",
        "\n",
        "    facebook/bart-large-mnli: Fine-tuned for natural language inference (NLI) tasks using the Multi-Genre Natural Language Inference (MNLI) dataset.\n",
        "\n",
        "    facebook/bart-large-xsum: Fine-tuned for extreme summarization tasks using the XSum dataset.\n",
        "\n",
        "    facebook/bart-large-squad2: Fine-tuned for question answering using the SQuAD 2.0 dataset."
      ],
      "metadata": {
        "id": "KYBjU5wsUPxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartForConditionalGeneration, BartTokenizer\n",
        "\n",
        "# Load the BART tokenizer and model\n",
        "model_name = \"facebook/bart-large-cnn\"\n",
        "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
        "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "# Function to summarize text\n",
        "def summarize_text(text, max_length=130, min_length=30, num_beams=4):\n",
        "    \"\"\"\n",
        "    Summarize the input text using BART.\n",
        "    :param text: str, input text to summarize\n",
        "    :param max_length: int, maximum length of the summary\n",
        "    :param min_length: int, minimum length of the summary\n",
        "    :param num_beams: int, number of beams for beam search\n",
        "    :return: str, summarized text\n",
        "    \"\"\"\n",
        "    inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
        "    summary_ids = model.generate(\n",
        "        inputs,\n",
        "        max_length=max_length,\n",
        "        min_length=min_length,\n",
        "        num_beams=num_beams,\n",
        "        early_stopping=True\n",
        "    )\n",
        "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n"
      ],
      "metadata": {
        "id": "FHNP2lg1SOxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model facebook/bart-large-cnn Details"
      ],
      "metadata": {
        "id": "HDi5E5SWVOeF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z01PRTSKUQ-E",
        "outputId": "d75ae8f6-067f-4e71-8a25-d11632e637fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BartForConditionalGeneration(\n",
              "  (model): BartModel(\n",
              "    (shared): BartScaledWordEmbedding(50264, 1024, padding_idx=1)\n",
              "    (encoder): BartEncoder(\n",
              "      (embed_tokens): BartScaledWordEmbedding(50264, 1024, padding_idx=1)\n",
              "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
              "      (layers): ModuleList(\n",
              "        (0-11): 12 x BartEncoderLayer(\n",
              "          (self_attn): BartSdpaAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (decoder): BartDecoder(\n",
              "      (embed_tokens): BartScaledWordEmbedding(50264, 1024, padding_idx=1)\n",
              "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
              "      (layers): ModuleList(\n",
              "        (0-11): 12 x BartDecoderLayer(\n",
              "          (self_attn): BartSdpaAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartSdpaAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (lm_head): Linear(in_features=1024, out_features=50264, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example usage bart model"
      ],
      "metadata": {
        "id": "a303dgBXVZV1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = (\n",
        "  \"\"\"Meta CEO Mark Zuckerberg has announced layoffs of what he refers to as \"low-performers\" at his empire.\n",
        "\n",
        "According to a company-wide memo obtained by Bloomberg, the Facebook owner is cutting around five percent of its staff. And interestingly, the directive is already in tension with what Zuckerberg told podcaster Joe Rogan last week about how the company was looking to replace \"midlevel engineers\" with AI. Instead — in a likely concession to AI just not quite being up to snuff yet — he says employees \"who aren't meeting expectations\" will be replaced in order to \"bring new people in\" (emphasis on the \"people,\" for any AI zealots.)\n",
        "\n",
        "\"I’ve decided to raise the bar on performance management and move out low-performers faster,\" he wrote in the message, adding that terminated employees would be provided with \"generous severance.\"\n",
        "\n",
        "Zuckerberg wrote that 2025 will be an \"intense year\" that will require the \"strongest talent.\" But what exactly he means by that remains unclear as the billionaire makes sweeping changes to the company's operations.\n",
        "\n",
        "The CEO appears to be taking yet another page out of the playbook of X-former-Twitter owner Elon Musk, who has long led his companies with an iron fist — demanding in 2022 that Twitter staff be \"extremely hardcore\" or risk immediate termination, for instance.\n",
        "\n",
        "Race to the Bottom\n",
        "\n",
        "Zuckerberg already raised eyebrows this month by giving up the pretense of serious content moderation on his sites. Earlier this month, he introduced new measures that would allow hate speech and misinformation to proliferate unchecked on the company's platforms, including Facebook, Instagram, and Threads.\n",
        "\n",
        "The straightforward reading is that it was a thinly veiled attempt by Zuckerberg to get in the good graces of president-elect Donald Trump, who has formed a tight relationship with Musk and will be sworn in next week (Trump previously threatened to imprison Zuckerberg, which may also be weighing on the founder's mind.)\n",
        "\n",
        "How exactly Meta's latest efforts to weed out \"low-performers\" fits into the ongoing groveling remains to be seen. It's not just Meta, either; tech companies across the board are looking to tighten up their operations. Microsoft is also targeting underperforming employees as part of major headcount reductions across the company.\n",
        "\n",
        "During his chat with Rogan last week, Zuckerberg also whined that companies were being \"culturally neutered\" by purportedly distancing themselves from \"masculine energy.\"\n",
        "\n",
        "Could his latest attempt to push out \"low-performers\" be symptomatic of his deranged desire to inject some machismo into Meta? Judging by the company's willingness to throw out the rulebook and double down on Musk-inspired meritocracy, anything seems possible.\n",
        "\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "Kp-xt4wfPC4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage \"facebook/bart-large-cnn\"\n",
        "\n",
        "summarized_text = summarize_text(input_text, max_length=1024)\n",
        "print(\"Original Text:\\n\", input_text)\n",
        "print(\"\\nSummarized Text:\\n\", summarized_text)\n",
        "print(\"input length: \", len(input_text))\n",
        "print(\"out put length: \", len(summarized_text))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghZtryW9MMk0",
        "outputId": "1c917c85-f678-49c0-ae4d-894959de3014"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text:\n",
            " Meta CEO Mark Zuckerberg has announced layoffs of what he refers to as \"low-performers\" at his empire.\n",
            "\n",
            "According to a company-wide memo obtained by Bloomberg, the Facebook owner is cutting around five percent of its staff. And interestingly, the directive is already in tension with what Zuckerberg told podcaster Joe Rogan last week about how the company was looking to replace \"midlevel engineers\" with AI. Instead — in a likely concession to AI just not quite being up to snuff yet — he says employees \"who aren't meeting expectations\" will be replaced in order to \"bring new people in\" (emphasis on the \"people,\" for any AI zealots.)\n",
            "\n",
            "\"I’ve decided to raise the bar on performance management and move out low-performers faster,\" he wrote in the message, adding that terminated employees would be provided with \"generous severance.\"\n",
            "\n",
            "Zuckerberg wrote that 2025 will be an \"intense year\" that will require the \"strongest talent.\" But what exactly he means by that remains unclear as the billionaire makes sweeping changes to the company's operations.\n",
            "\n",
            "The CEO appears to be taking yet another page out of the playbook of X-former-Twitter owner Elon Musk, who has long led his companies with an iron fist — demanding in 2022 that Twitter staff be \"extremely hardcore\" or risk immediate termination, for instance.\n",
            "\n",
            "Race to the Bottom\n",
            "\n",
            "Zuckerberg already raised eyebrows this month by giving up the pretense of serious content moderation on his sites. Earlier this month, he introduced new measures that would allow hate speech and misinformation to proliferate unchecked on the company's platforms, including Facebook, Instagram, and Threads.\n",
            "\n",
            "The straightforward reading is that it was a thinly veiled attempt by Zuckerberg to get in the good graces of president-elect Donald Trump, who has formed a tight relationship with Musk and will be sworn in next week (Trump previously threatened to imprison Zuckerberg, which may also be weighing on the founder's mind.)\n",
            "\n",
            "How exactly Meta's latest efforts to weed out \"low-performers\" fits into the ongoing groveling remains to be seen. It's not just Meta, either; tech companies across the board are looking to tighten up their operations. Microsoft is also targeting underperforming employees as part of major headcount reductions across the company.\n",
            "\n",
            "During his chat with Rogan last week, Zuckerberg also whined that companies were being \"culturally neutered\" by purportedly distancing themselves from \"masculine energy.\"\n",
            "\n",
            "Could his latest attempt to push out \"low-performers\" be symptomatic of his deranged desire to inject some machismo into Meta? Judging by the company's willingness to throw out the rulebook and double down on Musk-inspired meritocracy, anything seems possible.\n",
            "\n",
            "\n",
            "Summarized Text:\n",
            " #! Exper yet — he says employees \"who aren't meeting expectations will be replaced in order to \"bring new people in (emphasis on the \"people,\" for any AI zealots.)\n",
            "\n",
            "I’ve decided to raise the bar on performance management and move out low-performers faster,\" he wrote in the message, adding that terminated employees would be provided with \"generous severance.\"\n",
            "\n",
            "Zuckerberg wrote that 2025 will be an \"intense year that will require the \"strongest talent.\" But what exactly he means by that remains unclear as the billionaire makes sweeping changes to the company's operations.\n",
            "\n",
            "The CEO appears to be taking yet another page out of the playbook of X-former-Twitter owner Elon Musk, who has long led his companies with an iron fist — demanding in 2022 that Twitter staff be \"extremely hardcore or risk immediate termination, for instance.\n",
            " ArsenalRace to the Bottom\n",
            "\n",
            " Gavinuckerberg already raised eyebrows this month by giving up the pretense of serious content moderation on his sites. Earlier this month, he introduced new measures that would allow hate speech and misinformation to proliferate unchecked on the companyine platforms, including Facebook, Instagram, and Threads.\n",
            " burgers669 straightforward reading is that it was a thinly veiled attempt by Zuckerberg to get in the good graces of president-elect Donald Trump, who includ formed a tight relationship with Musk and will be sworn in next week (Trump previously threatened to imprison Zuckerberg, which may also be weighing on the founder's mind.)\n",
            "inaescapHow exactly Meta's latest efforts to weed out \"low- Trumpformers fits into the ongoing groveling remains to be seen. It's not just Meta, either; tech companies across the board are looking to tighten up their operations. Microsoft%#\n",
            "input length:  2732\n",
            "out put length:  1751\n"
          ]
        }
      ]
    }
  ]
}