>ANN_model_tf.py:

example dataset:
         age    fnlwgt  education_num  capital_gain  capital_loss  hours_per_week label
0  0.697613  0.023850      -0.202130     -0.200086     -0.267624        0.693308  >50K
1  1.246420  1.366554      -0.573692     -0.200086      3.546163        0.693308  >50K
2 -0.007997  0.172157       0.540995     -0.200086      3.728060        1.537879  >50K
3 -1.262414  0.842875      -0.202130      0.423228     -0.267624        0.524394  >50K
4 -0.478403 -0.431269       1.284119      0.423228     -0.267624       -0.573548  >50K
[5 rows x 7 columns]
columns name: ['age' 'fnlwgt' 'education_num' 'capital_gain' 'capital_loss'
 'hours_per_week' 'label']
labels size: (array(['<=50K', '>50K'], dtype=object), array([501, 499]))
dataset shape: (1000, 7)


Test accuracy: 0.50

Model: "sequential"
┌─────────────────────────────────┬────────────────────────┬───────────────┐
│ Layer (type)                    │ Output Shape           │       Param # │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 6)              │            42 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout (Dropout)               │ (None, 6)              │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_1 (Dense)                 │ (None, 8)              │            56 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_1 (Dropout)             │ (None, 8)              │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_2 (Dense)                 │ (None, 1)              │             9 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 107 (428.00 B)
 Trainable params: 107 (428.00 B)
 Non-trainable params: 0 (0.00 B)

Cross-validation scores: [0.45   0.4625 0.5    0.6125 0.45  ]

None
Layer: dense, Type: Dense
Layer: dropout, Type: Dropout
Layer: dense_1, Type: Dense
Layer: dropout_1, Type: Dropout
Layer: dense_2, Type: Dense

> ANN_model_pt.py
    id   age          job  marital  education default  balance housing loan   contact  day month  duration  campaign  pdays  previous poutcome   y
0   1  30.0   unemployed  married    primary      no     1787      no   no  cellular   19   oct        79         1     -1         0  unknown  no 
1   2  33.0     services  married  secondary      no     4789     yes  yes  cellular   11   may       220         1    339         4  failure  no 
2   3  35.0   management   single   tertiary      no     1350     yes   no  cellular   16   apr       185         1    330         1  failure  no 
3   4  30.0   management  married   tertiary      no     1476     yes  yes   unknown    3   jun       199         4     -1         0  unknown  no 
4   5  59.0  blue-collar  married  secondary      no        0     yes   no   unknown    5   may       226         1     -1         0  unknown  no 

[5 rows x 18 columns]

columns name: ['id' 'age' 'job' 'marital' 'education' 'default' 'balance' 'housing'
 'loan' 'contact' 'day' 'month' 'duration' 'campaign' 'pdays' 'previous'
 'poutcome' 'y']

target: ['no' 'yes']
shape: (4521, 18)

Null data:
id            0
age          39
job           0
marital       0
education     0
default       0
balance       0
housing       0
loan          0
contact       0
day           0
month         0
duration      0
campaign      0
pdays         0
previous      0
poutcome      0
y             0

dtype: int64
columns usage:  Index(['age', 'job', 'marital', 'education', 'balance', 'housing', 'loan',
       'campaign', 'pdays', 'previous', 'poutcome', 'y'],
      dtype='object')
category feature:  ['job' 'marital' 'housing' 'loan' 'poutcome' 'campaign']
ordinal features:  ['education']
numerical feature:  ['age' 'balance' 'pdays' 'previous']
Final X shape: (4507, 11), y shape: (4507,)

  self.scaler = GradScaler()  # For mixed precision training
Initial load data....
Start training data....
  with autocast():  # Mixed precision
Epoch 1/10, Train Loss: 0.8349, Train Acc: 0.8746, Val Loss: 0.7578, Val Acc: 0.8803
Epoch 2/10, Train Loss: 0.7310, Train Acc: 0.8871, Val Loss: 0.7048, Val Acc: 0.8803
Epoch 3/10, Train Loss: 0.7050, Train Acc: 0.8871, Val Loss: 0.6963, Val Acc: 0.8803
Epoch 4/10, Train Loss: 0.6996, Train Acc: 0.8871, Val Loss: 0.6944, Val Acc: 0.8803
Epoch 5/10, Train Loss: 0.6969, Train Acc: 0.8871, Val Loss: 0.6937, Val Acc: 0.8803
Epoch 6/10, Train Loss: 0.6958, Train Acc: 0.8871, Val Loss: 0.6935, Val Acc: 0.8803
Epoch 7/10, Train Loss: 0.6949, Train Acc: 0.8871, Val Loss: 0.6933, Val Acc: 0.8803
Epoch 8/10, Train Loss: 0.6944, Train Acc: 0.8871, Val Loss: 0.6933, Val Acc: 0.8803
Epoch 9/10, Train Loss: 0.6949, Train Acc: 0.8871, Val Loss: 0.6932, Val Acc: 0.8803
Epoch 10/10, Train Loss: 0.6941, Train Acc: 0.8871, Val Loss: 0.6932, Val Acc: 0.8803
Finished training data....

Cross-validation scores: [0.81276006 0.84604716 0.84604716 0.87517337 0.82801664]
Average CV accuracy: 0.8416088765603329

Test accuracy: 0.88

Model training complete..........
Model and training history saved!

Feature names after preprocessing: 
['cat__job_admin.' 'cat__job_blue-collar' 'cat__job_entrepreneur'
 'cat__job_housemaid' 'cat__job_management' 'cat__job_retired'
 'cat__job_self-employed' 'cat__job_services' 'cat__job_student'
 'cat__job_technician' 'cat__job_unemployed' 'cat__job_unknown'
 'cat__marital_divorced' 'cat__marital_married' 'cat__marital_single'
 'cat__education_primary' 'cat__education_secondary'
 'cat__education_tertiary' 'cat__education_unknown' 'cat__housing_no'
 'cat__housing_yes' 'cat__loan_no' 'cat__loan_yes' 'cat__poutcome_failure'
 'cat__poutcome_other' 'cat__poutcome_success' 'cat__poutcome_unknown'
 'cat__campaign_1' 'cat__campaign_2' 'cat__campaign_3' 'cat__campaign_4'
 'cat__campaign_5' 'cat__campaign_6' 'cat__campaign_7' 'cat__campaign_8'
 'cat__campaign_9' 'cat__campaign_10' 'cat__campaign_11'
 'cat__campaign_12' 'cat__campaign_13' 'cat__campaign_14'
 'cat__campaign_15' 'cat__campaign_16' 'cat__campaign_17'
 'cat__campaign_18' 'cat__campaign_19' 'cat__campaign_20'
 'cat__campaign_21' 'cat__campaign_22' 'cat__campaign_23'
 'cat__campaign_24' 'cat__campaign_25' 'cat__campaign_28'
 'cat__campaign_29' 'cat__campaign_30' 'cat__campaign_31'
 'cat__campaign_32' 'cat__campaign_44' 'cat__campaign_50' 'num__age'
 'num__balance' 'num__pdays' 'num__previous']

 Model get prediction..........
[[0]
 [0]
 [0]
 [0]
 [0]]

 >> ANN_usage_pt.py
Model Architecture:
TorchModel(
  (fc1): Linear(in_features=11, out_features=6, bias=True)
  (fc2): Linear(in_features=6, out_features=6, bias=True)
  (dropout): Dropout(p=0.3, inplace=False)
  (fc3): Linear(in_features=6, out_features=1, bias=True)
)

Model get prediction..........
[0 0 0 0 0]

> CNN_model.py :

Model: "sequential"
┌─────────────────────────────────┬────────────────────────┬───────────────┐
│ Layer (type)                    │ Output Shape           │       Param # │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d (Conv2D)                 │ (None, 26, 26, 32)     │           320 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling2d (MaxPooling2D)    │ (None, 13, 13, 32)     │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_1 (Conv2D)               │ (None, 11, 11, 64)     │        18,496 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling2d_1 (MaxPooling2D)  │ (None, 5, 5, 64)       │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_2 (Conv2D)               │ (None, 3, 3, 64)       │        36,928 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ flatten (Flatten)               │ (None, 576)            │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 64)             │        36,928 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout (Dropout)               │ (None, 64)             │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_1 (Dense)                 │ (None, 10)             │           650 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 93,322 (364.54 KB)
 Trainable params: 93,322 (364.54 KB)
 Non-trainable params: 0 (0.00 B)

Final Training Accuracy: 0.9932
Final Validation Accuracy: 0.9881
Training Loss: 0.0223
Validation Loss: 0.0542

Evaluating model on test set...
Test Set Accuracy: 0.9897

