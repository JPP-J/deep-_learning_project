>ANN_model_tf.py:

example dataset:
         age    fnlwgt  education_num  capital_gain  capital_loss  hours_per_week label
0  0.697613  0.023850      -0.202130     -0.200086     -0.267624        0.693308  >50K
1  1.246420  1.366554      -0.573692     -0.200086      3.546163        0.693308  >50K
2 -0.007997  0.172157       0.540995     -0.200086      3.728060        1.537879  >50K
3 -1.262414  0.842875      -0.202130      0.423228     -0.267624        0.524394  >50K
4 -0.478403 -0.431269       1.284119      0.423228     -0.267624       -0.573548  >50K
[5 rows x 7 columns]
columns name: ['age' 'fnlwgt' 'education_num' 'capital_gain' 'capital_loss'
 'hours_per_week' 'label']
labels size: (array(['<=50K', '>50K'], dtype=object), array([501, 499]))
dataset shape: (1000, 7)

Epoch 1/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 2s 9ms/step - accuracy: 0.6354 - loss: 0.6726 - val_accuracy: 0.6719 - val_loss: 0.6052
Epoch 2/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.7330 - loss: 0.5464 - val_accuracy: 0.6719 - val_loss: 0.5725
Epoch 3/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.7669 - loss: 0.5069 - val_accuracy: 0.7031 - val_loss: 0.5617
Epoch 4/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.7750 - loss: 0.4722 - val_accuracy: 0.6797 - val_loss: 0.5719
Epoch 5/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.7780 - loss: 0.4923 - val_accuracy: 0.6953 - val_loss: 0.5587
Epoch 6/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.7555 - loss: 0.4912 - val_accuracy: 0.7031 - val_loss: 0.5535
Epoch 7/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.7679 - loss: 0.4803 - val_accuracy: 0.6953 - val_loss: 0.5563
Epoch 8/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.7720 - loss: 0.4665 - val_accuracy: 0.6875 - val_loss: 0.5587
Epoch 9/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.7774 - loss: 0.4555 - val_accuracy: 0.7188 - val_loss: 0.5543
Epoch 10/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.7836 - loss: 0.4358 - val_accuracy: 0.7188 - val_loss: 0.5658
Epoch 11/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.7834 - loss: 0.4623 - val_accuracy: 0.7266 - val_loss: 0.5457
Epoch 12/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.7689 - loss: 0.4424 - val_accuracy: 0.7344 - val_loss: 0.5624
Epoch 13/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.7786 - loss: 0.4363 - val_accuracy: 0.7344 - val_loss: 0.5560
Epoch 14/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.7870 - loss: 0.4528 - val_accuracy: 0.7266 - val_loss: 0.5683
Epoch 15/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.7908 - loss: 0.4389 - val_accuracy: 0.7422 - val_loss: 0.5683
Epoch 16/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.7931 - loss: 0.4231 - val_accuracy: 0.7422 - val_loss: 0.5697
Epoch 17/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.7833 - loss: 0.4284 - val_accuracy: 0.7422 - val_loss: 0.5644
Epoch 18/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.7970 - loss: 0.4257 - val_accuracy: 0.7422 - val_loss: 0.5766
Epoch 19/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step - accuracy: 0.8027 - loss: 0.4132 - val_accuracy: 0.7188 - val_loss: 0.5745
Epoch 20/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.7791 - loss: 0.4284 - val_accuracy: 0.7344 - val_loss: 0.5810
Epoch 21/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step - accuracy: 0.7968 - loss: 0.4125 - val_accuracy: 0.7266 - val_loss: 0.5878
Epoch 22/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.7904 - loss: 0.3992 - val_accuracy: 0.7109 - val_loss: 0.6058
Epoch 23/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.7949 - loss: 0.4085 - val_accuracy: 0.7422 - val_loss: 0.5891
Epoch 24/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8019 - loss: 0.4196 - val_accuracy: 0.7188 - val_loss: 0.5914
Epoch 25/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8025 - loss: 0.3933 - val_accuracy: 0.7109 - val_loss: 0.6021
Epoch 26/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8165 - loss: 0.3738 - val_accuracy: 0.7188 - val_loss: 0.6141

Cross-validation scores: [0.70625 0.75625 0.76875 0.7     0.7375 ]
Test accuracy: 0.70
Model: "sequential"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
│ dense (Dense)                        │ (None, 64)                  │             448 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dense_1 (Dense)                      │ (None, 64)                  │           4,160 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dropout (Dropout)                    │ (None, 64)                  │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dense_2 (Dense)                      │ (None, 64)                  │           4,160 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dropout_1 (Dropout)                  │ (None, 64)                  │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dense_3 (Dense)                      │ (None, 64)                  │           4,160 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dropout_2 (Dropout)                  │ (None, 64)                  │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dense_4 (Dense)                      │ (None, 1)                   │              65 │
└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
 Total params: 38,981 (152.27 KB)
 Trainable params: 12,993 (50.75 KB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 25,988 (101.52 KB)

-------------------------------------------------------------------------------------------------------------------------------
> ANN_model_pt.py
    id   age          job  marital  education default  balance housing loan   contact  day month  duration  campaign  pdays  previous poutcome   y
0   1  30.0   unemployed  married    primary      no     1787      no   no  cellular   19   oct        79         1     -1         0  unknown  no 
1   2  33.0     services  married  secondary      no     4789     yes  yes  cellular   11   may       220         1    339         4  failure  no 
2   3  35.0   management   single   tertiary      no     1350     yes   no  cellular   16   apr       185         1    330         1  failure  no 
3   4  30.0   management  married   tertiary      no     1476     yes  yes   unknown    3   jun       199         4     -1         0  unknown  no 
4   5  59.0  blue-collar  married  secondary      no        0     yes   no   unknown    5   may       226         1     -1         0  unknown  no 

[5 rows x 18 columns]

columns name: ['id' 'age' 'job' 'marital' 'education' 'default' 'balance' 'housing'
 'loan' 'contact' 'day' 'month' 'duration' 'campaign' 'pdays' 'previous'
 'poutcome' 'y']

target: ['no' 'yes']
shape: (4521, 18)

Null data:
id            0
age          39
job           0
marital       0
education     0
default       0
balance       0
housing       0
loan          0
contact       0
day           0
month         0
duration      0
campaign      0
pdays         0
previous      0
poutcome      0
y             0

dtype: int64
columns usage:  Index(['age', 'job', 'marital', 'education', 'balance', 'housing', 'loan',
       'campaign', 'pdays', 'previous', 'poutcome', 'y'],
      dtype='object')
category feature:  ['job' 'marital' 'housing' 'loan' 'poutcome' 'campaign']
ordinal features:  ['education']
numerical feature:  ['age' 'balance' 'pdays' 'previous']
Final X shape: (4507, 11), y shape: (4507,)

  self.scaler = GradScaler()  # For mixed precision training
Initial load data....
Start training data....
  with autocast():  # Mixed precision
Epoch 1/10, Train Loss: 0.8349, Train Acc: 0.8746, Val Loss: 0.7578, Val Acc: 0.8803
Epoch 2/10, Train Loss: 0.7310, Train Acc: 0.8871, Val Loss: 0.7048, Val Acc: 0.8803
Epoch 3/10, Train Loss: 0.7050, Train Acc: 0.8871, Val Loss: 0.6963, Val Acc: 0.8803
Epoch 4/10, Train Loss: 0.6996, Train Acc: 0.8871, Val Loss: 0.6944, Val Acc: 0.8803
Epoch 5/10, Train Loss: 0.6969, Train Acc: 0.8871, Val Loss: 0.6937, Val Acc: 0.8803
Epoch 6/10, Train Loss: 0.6958, Train Acc: 0.8871, Val Loss: 0.6935, Val Acc: 0.8803
Epoch 7/10, Train Loss: 0.6949, Train Acc: 0.8871, Val Loss: 0.6933, Val Acc: 0.8803
Epoch 8/10, Train Loss: 0.6944, Train Acc: 0.8871, Val Loss: 0.6933, Val Acc: 0.8803
Epoch 9/10, Train Loss: 0.6949, Train Acc: 0.8871, Val Loss: 0.6932, Val Acc: 0.8803
Epoch 10/10, Train Loss: 0.6941, Train Acc: 0.8871, Val Loss: 0.6932, Val Acc: 0.8803
Finished training data....

Cross-validation scores: [0.81276006 0.84604716 0.84604716 0.87517337 0.82801664]
Average CV accuracy: 0.8416088765603329

Test accuracy: 0.88

Model training complete..........
Model and training history saved!

Feature names after preprocessing: 
['cat__job_admin.' 'cat__job_blue-collar' 'cat__job_entrepreneur'
 'cat__job_housemaid' 'cat__job_management' 'cat__job_retired'
 'cat__job_self-employed' 'cat__job_services' 'cat__job_student'
 'cat__job_technician' 'cat__job_unemployed' 'cat__job_unknown'
 'cat__marital_divorced' 'cat__marital_married' 'cat__marital_single'
 'cat__education_primary' 'cat__education_secondary'
 'cat__education_tertiary' 'cat__education_unknown' 'cat__housing_no'
 'cat__housing_yes' 'cat__loan_no' 'cat__loan_yes' 'cat__poutcome_failure'
 'cat__poutcome_other' 'cat__poutcome_success' 'cat__poutcome_unknown'
 'cat__campaign_1' 'cat__campaign_2' 'cat__campaign_3' 'cat__campaign_4'
 'cat__campaign_5' 'cat__campaign_6' 'cat__campaign_7' 'cat__campaign_8'
 'cat__campaign_9' 'cat__campaign_10' 'cat__campaign_11'
 'cat__campaign_12' 'cat__campaign_13' 'cat__campaign_14'
 'cat__campaign_15' 'cat__campaign_16' 'cat__campaign_17'
 'cat__campaign_18' 'cat__campaign_19' 'cat__campaign_20'
 'cat__campaign_21' 'cat__campaign_22' 'cat__campaign_23'
 'cat__campaign_24' 'cat__campaign_25' 'cat__campaign_28'
 'cat__campaign_29' 'cat__campaign_30' 'cat__campaign_31'
 'cat__campaign_32' 'cat__campaign_44' 'cat__campaign_50' 'num__age'
 'num__balance' 'num__pdays' 'num__previous']

 Model get prediction..........
[[0]
 [0]
 [0]
 [0]
 [0]]

 >> ANN_usage_pt.py
Model Architecture:
TorchModel(
  (fc1): Linear(in_features=11, out_features=6, bias=True)
  (fc2): Linear(in_features=6, out_features=6, bias=True)
  (dropout): Dropout(p=0.3, inplace=False)
  (fc3): Linear(in_features=6, out_features=1, bias=True)
)

Model get prediction..........
[0 0 0 0 0]

> CNN_model.py :

Model: "sequential"
┌─────────────────────────────────┬────────────────────────┬───────────────┐
│ Layer (type)                    │ Output Shape           │       Param # │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d (Conv2D)                 │ (None, 26, 26, 32)     │           320 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling2d (MaxPooling2D)    │ (None, 13, 13, 32)     │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_1 (Conv2D)               │ (None, 11, 11, 64)     │        18,496 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling2d_1 (MaxPooling2D)  │ (None, 5, 5, 64)       │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_2 (Conv2D)               │ (None, 3, 3, 64)       │        36,928 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ flatten (Flatten)               │ (None, 576)            │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 64)             │        36,928 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout (Dropout)               │ (None, 64)             │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_1 (Dense)                 │ (None, 10)             │           650 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 93,322 (364.54 KB)
 Trainable params: 93,322 (364.54 KB)
 Non-trainable params: 0 (0.00 B)

Final Training Accuracy: 0.9932
Final Validation Accuracy: 0.9881
Training Loss: 0.0223
Validation Loss: 0.0542

Evaluating model on test set...
Test Set Accuracy: 0.9897

